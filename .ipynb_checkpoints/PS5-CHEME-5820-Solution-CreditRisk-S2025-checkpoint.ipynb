{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd638f86-ae37-4d57-90b7-6b3d506eb03a",
   "metadata": {},
   "source": [
    "# PS5: Classification of Consumer Credit Score\n",
    "In this problem, we will construct, train, and evaluate a feedforward neural network to classify consumer credit scores.\n",
    "\n",
    "* _What is a credit score?_ A credit score is a numerical expression based on analyzing a person's credit files to represent that person's creditworthiness. It is primarily based on credit report information, typically sourced from credit bureaus. Lenders use the score to evaluate the potential risk posed by lending money to consumers and to mitigate losses due to bad debt. The score is a three-digit number ranging from 300 to 850, with higher scores indicating lower risk.\n",
    "* _Hypothetical scenario:_  You are a data scientist working in a global manufacturing company, e.g., [GM](https://www.gm.com), [Honda](https://automobiles.honda.com/?experience=shop&cid=search_google_hgr_low_general_namy-brand_sustain-general_nalng_brd_exact&gclsrc=aw.ds&gad_source=1&gad_campaignid=176299752&gbraid=0AAAAADrc52ELssuW_I6a3tbwGwhvLOOAk&gclid=Cj0KCQjwtpLABhC7ARIsALBOCVryBRVf6m-hXR3JBoFgGcKEg1W6vvyxd2j0qhXqHbrHY1qF3J2SapUaAix4EALw_wcB) or [Caterpillar](https://www.caterpillar.com), etc. Over the past few years, your company has collected basic bank details and gathered credit-related information on customers when they finance the purchase of products through your credit division, e.g., [GM Financial](https://www.gmfinancial.com/en-us/home.html), [Honda Financial Services](https://login.honda.com/hondafinance/s/login/?ec=302&startURL=%2Fhondafinance%2Fs%2F), or [CAT Financial](https://www.caterpillar.com/en/brands/cat-financial.html). You have been tasked with building an intelligent system to classify customers into credit score brackets to reduce manual efforts, speed up loan processing, and impact the top-line sales for your company.\n",
    "\n",
    "### Tasks\n",
    "Before you start, execute the `Run All Cells` command to check if you have any code or setup issues. Code issues, post them [to Ed Discussion](https://edstem.org/) - and let's get those fixed!\n",
    "\n",
    "* __Task 1: Setup, Data, Constants__: In this task, we set up the computational environment, load the necessary packages, and prepare the training and test data for the consumer credit classification problem. We will also define any constants we use throughout the problem set.\n",
    "* __Task 2: Construct and Train a Feedforward Credit Score Classifier__: In this task, we'll construct and train a feedforward neural network model using the training records encoded in the `training_dataset::Vector{Tuple{Vector{Float32}, OneHotVector{UInt32}}}` array. This model will classify consumers' credit scores based on their features. We will use [the `Flux.jl` package](https://github.com/FluxML/Flux.jl) to build and train the model.\n",
    "* __Task 3: Does the model generalize?__ In this task, we'll check the feedforward network's ability to generalize, i.e., calculate how well the network classifies records it has not seen. We'll compute the fraction of the training and test data that is correctly classified, and answer some design questions.\n",
    "\n",
    "Tests throughout the notebook (and at the bottom section) help you determine if things are running correctly. Let's go! (Remember to answer the discussion questions.)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f483cd66",
   "metadata": {},
   "source": [
    "## Task 1: Setup, Data, and Prerequisites\n",
    "In this task, we'll set up the computational environment, load the necessary packages, and prepare the `world(...)` function for our personal shopper problem. We will also define any constants we use throughout the problem set.\n",
    "\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. \n",
    "* The `Include.jl` file also loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem. It checks for a `Manifest.toml` file; if it finds one, packages are loaded. Other packages are downloaded and then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f3cd9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\"); # This will load necessary packages and functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c656ea",
   "metadata": {},
   "source": [
    "### Data\n",
    "Suppose we have a dataset $\\mathcal{D} = \\left\\{(\\mathbf{x}_{1},y_{1}),(\\mathbf{x}_{2},y_{2}),\\dots,(\\mathbf{x}_{n},y_{n})\\right\\}$ containing $n$ records, where each record is a tuple $(\\mathbf{x}, y)$, where $\\mathbf{x} \\in \\mathbb{R}^m$ is a vector of features and $y \\in \\mathcal{Y}$ is a label. The label $y$ is a categorical variable that can take on one of three values: $\\mathcal{Y} \\equiv \\left\\{\\texttt{Poor},\\texttt{Standard},\\texttt{Good}\\right\\}$. We'll start by loading the raw data. The raw dataset is a CSV file containing information about consumer credit score, and is [available on Kaggle](https://www.kaggle.com/datasets/sudhanshu2198/processed-data-credit-score?resource=download). \n",
    "* _What's in the dataset?_ The dataset contains apporimately 99k records, where each record contains `21` feature variables related to consumer credit, such as income, age, and other relevant attributes that may influence credit risk. The label variable for each record indicates whether the consumer is a good or bad credit risk, i.e., has a `(Poor | Standard | Good)` credit score. \n",
    "\n",
    "Let's load the raw dataset, and save it in the raw data in the `raw_data::DataFrame` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f46b1168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>99960×21 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">99935 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Delay_from_due_date</th><th style = \"text-align: left;\">Num_of_Delayed_Payment</th><th style = \"text-align: left;\">Num_Credit_Inquiries</th><th style = \"text-align: left;\">Credit_Utilization_Ratio</th><th style = \"text-align: left;\">Credit_History_Age</th><th style = \"text-align: left;\">Payment_of_Min_Amount</th><th style = \"text-align: left;\">Amount_invested_monthly</th><th style = \"text-align: left;\">Monthly_Balance</th><th style = \"text-align: left;\">Credit_Score</th><th style = \"text-align: left;\">Credit_Mix</th><th style = \"text-align: left;\">Payment_Behaviour</th><th style = \"text-align: left;\">Age</th><th style = \"text-align: left;\">Annual_Income</th><th style = \"text-align: left;\">Num_Bank_Accounts</th><th style = \"text-align: left;\">Num_Credit_Card</th><th style = \"text-align: left;\">Interest_Rate</th><th style = \"text-align: left;\">Num_of_Loan</th><th style = \"text-align: left;\">Monthly_Inhand_Salary</th><th style = \"text-align: left;\">Changed_Credit_Limit</th><th style = \"text-align: left;\">Outstanding_Debt</th><th style = \"text-align: left;\">Total_EMI_per_month</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String3\" style = \"text-align: left;\">String3</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">26.8226</td><td style = \"text-align: right;\">265.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">80.4153</td><td style = \"text-align: right;\">312.494</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">23.0</td><td style = \"text-align: right;\">19114.1</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">1824.84</td><td style = \"text-align: right;\">11.27</td><td style = \"text-align: right;\">809.98</td><td style = \"text-align: right;\">49.5749</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">31.945</td><td style = \"text-align: right;\">265.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">118.28</td><td style = \"text-align: right;\">284.629</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">23.0</td><td style = \"text-align: right;\">19114.1</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">1824.84</td><td style = \"text-align: right;\">11.27</td><td style = \"text-align: right;\">809.98</td><td style = \"text-align: right;\">49.5749</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">28.6094</td><td style = \"text-align: right;\">267.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">81.6995</td><td style = \"text-align: right;\">331.21</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">23.0</td><td style = \"text-align: right;\">19114.1</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">1824.84</td><td style = \"text-align: right;\">11.27</td><td style = \"text-align: right;\">809.98</td><td style = \"text-align: right;\">49.5749</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">31.3779</td><td style = \"text-align: right;\">268.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">199.458</td><td style = \"text-align: right;\">223.451</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">23.0</td><td style = \"text-align: right;\">19114.1</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">1824.84</td><td style = \"text-align: right;\">11.27</td><td style = \"text-align: right;\">809.98</td><td style = \"text-align: right;\">49.5749</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">24.7973</td><td style = \"text-align: right;\">269.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">41.4202</td><td style = \"text-align: right;\">341.489</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">23.0</td><td style = \"text-align: right;\">19114.1</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">1824.84</td><td style = \"text-align: right;\">11.27</td><td style = \"text-align: right;\">809.98</td><td style = \"text-align: right;\">49.5749</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">8.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">27.2623</td><td style = \"text-align: right;\">270.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">62.4302</td><td style = \"text-align: right;\">340.479</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">23.0</td><td style = \"text-align: right;\">19114.1</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">1824.84</td><td style = \"text-align: right;\">11.27</td><td style = \"text-align: right;\">809.98</td><td style = \"text-align: right;\">49.5749</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">8.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">22.5376</td><td style = \"text-align: right;\">271.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">178.344</td><td style = \"text-align: right;\">244.565</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">23.0</td><td style = \"text-align: right;\">19114.1</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">1824.84</td><td style = \"text-align: right;\">11.27</td><td style = \"text-align: right;\">809.98</td><td style = \"text-align: right;\">49.5749</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">23.9338</td><td style = \"text-align: right;\">271.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">24.7852</td><td style = \"text-align: right;\">358.124</td><td style = \"text-align: left;\">Standard</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">23.0</td><td style = \"text-align: right;\">19114.1</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">1824.84</td><td style = \"text-align: right;\">11.27</td><td style = \"text-align: right;\">809.98</td><td style = \"text-align: right;\">49.5749</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">24.464</td><td style = \"text-align: right;\">319.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">104.292</td><td style = \"text-align: right;\">470.691</td><td style = \"text-align: left;\">Standard</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Large_value_payments</td><td style = \"text-align: right;\">28.0</td><td style = \"text-align: right;\">34847.8</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">3037.99</td><td style = \"text-align: right;\">5.42</td><td style = \"text-align: right;\">605.03</td><td style = \"text-align: right;\">18.8162</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">38.5508</td><td style = \"text-align: right;\">320.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">40.3912</td><td style = \"text-align: right;\">484.591</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Large_value_payments</td><td style = \"text-align: right;\">28.0</td><td style = \"text-align: right;\">34847.8</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">3037.99</td><td style = \"text-align: right;\">5.42</td><td style = \"text-align: right;\">605.03</td><td style = \"text-align: right;\">18.8162</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">33.225</td><td style = \"text-align: right;\">321.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">58.516</td><td style = \"text-align: right;\">466.466</td><td style = \"text-align: left;\">Standard</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Large_value_payments</td><td style = \"text-align: right;\">28.0</td><td style = \"text-align: right;\">34847.8</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">3037.99</td><td style = \"text-align: right;\">5.42</td><td style = \"text-align: right;\">605.03</td><td style = \"text-align: right;\">18.8162</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">39.1827</td><td style = \"text-align: right;\">322.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">99.3062</td><td style = \"text-align: right;\">465.676</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Large_value_payments</td><td style = \"text-align: right;\">28.0</td><td style = \"text-align: right;\">34847.8</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">3037.99</td><td style = \"text-align: right;\">5.42</td><td style = \"text-align: right;\">605.03</td><td style = \"text-align: right;\">18.8162</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">34.9779</td><td style = \"text-align: right;\">323.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">130.115</td><td style = \"text-align: right;\">444.867</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Large_value_payments</td><td style = \"text-align: right;\">28.0</td><td style = \"text-align: right;\">34847.8</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">3037.99</td><td style = \"text-align: right;\">5.42</td><td style = \"text-align: right;\">605.03</td><td style = \"text-align: right;\">18.8162</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99949</td><td style = \"text-align: right;\">33.0</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">9.0</td><td style = \"text-align: right;\">28.5083</td><td style = \"text-align: right;\">72.0</td><td style = \"text-align: left;\">Yes</td><td style = \"text-align: right;\">213.978</td><td style = \"text-align: right;\">208.048</td><td style = \"text-align: left;\">Standard</td><td style = \"text-align: left;\">Bad</td><td style = \"text-align: left;\">High_spent_Large_value_payments</td><td style = \"text-align: right;\">28.0</td><td style = \"text-align: right;\">20002.9</td><td style = \"text-align: right;\">10.0</td><td style = \"text-align: right;\">8.0</td><td style = \"text-align: right;\">29.0</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">1929.91</td><td style = \"text-align: right;\">18.31</td><td style = \"text-align: right;\">3571.7</td><td style = \"text-align: right;\">60.9648</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99950</td><td style = \"text-align: right;\">33.0</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">9.0</td><td style = \"text-align: right;\">33.36</td><td style = \"text-align: right;\">73.0</td><td style = \"text-align: left;\">Yes</td><td style = \"text-align: right;\">74.3666</td><td style = \"text-align: right;\">307.659</td><td style = \"text-align: left;\">Standard</td><td style = \"text-align: left;\">Bad</td><td style = \"text-align: left;\">High_spent_Large_value_payments</td><td style = \"text-align: right;\">28.0</td><td style = \"text-align: right;\">20002.9</td><td style = \"text-align: right;\">10.0</td><td style = \"text-align: right;\">8.0</td><td style = \"text-align: right;\">29.0</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">1929.91</td><td style = \"text-align: right;\">18.31</td><td style = \"text-align: right;\">3571.7</td><td style = \"text-align: right;\">60.9648</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99951</td><td style = \"text-align: right;\">33.0</td><td style = \"text-align: right;\">26.0</td><td style = \"text-align: right;\">9.0</td><td style = \"text-align: right;\">25.1235</td><td style = \"text-align: right;\">73.0</td><td style = \"text-align: left;\">Yes</td><td style = \"text-align: right;\">173.276</td><td style = \"text-align: right;\">228.75</td><td style = \"text-align: left;\">Standard</td><td style = \"text-align: left;\">Bad</td><td style = \"text-align: left;\">High_spent_Large_value_payments</td><td style = \"text-align: right;\">28.0</td><td style = \"text-align: right;\">20002.9</td><td style = \"text-align: right;\">10.0</td><td style = \"text-align: right;\">8.0</td><td style = \"text-align: right;\">29.0</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">1929.91</td><td style = \"text-align: right;\">18.31</td><td style = \"text-align: right;\">3571.7</td><td style = \"text-align: right;\">60.9648</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99952</td><td style = \"text-align: right;\">33.0</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">9.0</td><td style = \"text-align: right;\">37.1408</td><td style = \"text-align: right;\">75.0</td><td style = \"text-align: left;\">Yes</td><td style = \"text-align: right;\">34.6629</td><td style = \"text-align: right;\">337.363</td><td style = \"text-align: left;\">Standard</td><td style = \"text-align: left;\">Bad</td><td style = \"text-align: left;\">High_spent_Large_value_payments</td><td style = \"text-align: right;\">28.0</td><td style = \"text-align: right;\">20002.9</td><td style = \"text-align: right;\">10.0</td><td style = \"text-align: right;\">8.0</td><td style = \"text-align: right;\">29.0</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: right;\">1929.91</td><td style = \"text-align: right;\">18.31</td><td style = \"text-align: right;\">3571.7</td><td style = \"text-align: right;\">60.9648</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99953</td><td style = \"text-align: right;\">23.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">32.9913</td><td style = \"text-align: right;\">375.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">401.196</td><td style = \"text-align: right;\">189.641</td><td style = \"text-align: left;\">Poor</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">39629.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">3359.42</td><td style = \"text-align: right;\">11.5</td><td style = \"text-align: right;\">502.38</td><td style = \"text-align: right;\">35.104</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99954</td><td style = \"text-align: right;\">23.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">29.1354</td><td style = \"text-align: right;\">376.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">180.733</td><td style = \"text-align: right;\">400.104</td><td style = \"text-align: left;\">Standard</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">39629.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">3359.42</td><td style = \"text-align: right;\">11.5</td><td style = \"text-align: right;\">502.38</td><td style = \"text-align: right;\">35.104</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99955</td><td style = \"text-align: right;\">20.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">39.3236</td><td style = \"text-align: right;\">377.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">140.581</td><td style = \"text-align: right;\">410.256</td><td style = \"text-align: left;\">Poor</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">39629.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">3359.42</td><td style = \"text-align: right;\">11.5</td><td style = \"text-align: right;\">502.38</td><td style = \"text-align: right;\">35.104</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99956</td><td style = \"text-align: right;\">23.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">34.6636</td><td style = \"text-align: right;\">378.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">60.9713</td><td style = \"text-align: right;\">479.866</td><td style = \"text-align: left;\">Poor</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">39629.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">3359.42</td><td style = \"text-align: right;\">11.5</td><td style = \"text-align: right;\">502.38</td><td style = \"text-align: right;\">35.104</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99957</td><td style = \"text-align: right;\">18.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">40.5656</td><td style = \"text-align: right;\">379.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">54.186</td><td style = \"text-align: right;\">496.652</td><td style = \"text-align: left;\">Poor</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">39629.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">3359.42</td><td style = \"text-align: right;\">11.5</td><td style = \"text-align: right;\">502.38</td><td style = \"text-align: right;\">35.104</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99958</td><td style = \"text-align: right;\">27.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">41.2555</td><td style = \"text-align: right;\">380.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">24.0285</td><td style = \"text-align: right;\">516.809</td><td style = \"text-align: left;\">Poor</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">39629.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">3359.42</td><td style = \"text-align: right;\">11.5</td><td style = \"text-align: right;\">502.38</td><td style = \"text-align: right;\">35.104</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99959</td><td style = \"text-align: right;\">20.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">33.6382</td><td style = \"text-align: right;\">381.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">251.673</td><td style = \"text-align: right;\">319.165</td><td style = \"text-align: left;\">Standard</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">39629.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">3359.42</td><td style = \"text-align: right;\">11.5</td><td style = \"text-align: right;\">502.38</td><td style = \"text-align: right;\">35.104</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99960</td><td style = \"text-align: right;\">18.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">3.0</td><td style = \"text-align: right;\">34.1925</td><td style = \"text-align: right;\">382.0</td><td style = \"text-align: left;\">No</td><td style = \"text-align: right;\">167.164</td><td style = \"text-align: right;\">393.674</td><td style = \"text-align: left;\">Poor</td><td style = \"text-align: left;\">Good</td><td style = \"text-align: left;\">High_spent_Medium_value_payments</td><td style = \"text-align: right;\">25.0</td><td style = \"text-align: right;\">39629.0</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: right;\">6.0</td><td style = \"text-align: right;\">7.0</td><td style = \"text-align: right;\">2.0</td><td style = \"text-align: right;\">3359.42</td><td style = \"text-align: right;\">11.5</td><td style = \"text-align: right;\">502.38</td><td style = \"text-align: right;\">35.104</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& Delay\\_from\\_due\\_date & Num\\_of\\_Delayed\\_Payment & Num\\_Credit\\_Inquiries & Credit\\_Utilization\\_Ratio & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 3.0 & 7.0 & 4.0 & 26.8226 & $\\dots$ \\\\\n",
       "\t2 & 3.0 & 7.0 & 4.0 & 31.945 & $\\dots$ \\\\\n",
       "\t3 & 3.0 & 7.0 & 4.0 & 28.6094 & $\\dots$ \\\\\n",
       "\t4 & 5.0 & 4.0 & 4.0 & 31.3779 & $\\dots$ \\\\\n",
       "\t5 & 6.0 & 4.0 & 4.0 & 24.7973 & $\\dots$ \\\\\n",
       "\t6 & 8.0 & 4.0 & 4.0 & 27.2623 & $\\dots$ \\\\\n",
       "\t7 & 3.0 & 8.0 & 4.0 & 22.5376 & $\\dots$ \\\\\n",
       "\t8 & 3.0 & 6.0 & 4.0 & 23.9338 & $\\dots$ \\\\\n",
       "\t9 & 3.0 & 4.0 & 2.0 & 24.464 & $\\dots$ \\\\\n",
       "\t10 & 7.0 & 1.0 & 2.0 & 38.5508 & $\\dots$ \\\\\n",
       "\t11 & 3.0 & 1.0 & 2.0 & 33.225 & $\\dots$ \\\\\n",
       "\t12 & 3.0 & 3.0 & 2.0 & 39.1827 & $\\dots$ \\\\\n",
       "\t13 & 3.0 & 1.0 & 2.0 & 34.9779 & $\\dots$ \\\\\n",
       "\t14 & 3.0 & 0.0 & 2.0 & 33.381 & $\\dots$ \\\\\n",
       "\t15 & 3.0 & 4.0 & 2.0 & 31.1317 & $\\dots$ \\\\\n",
       "\t16 & 3.0 & 4.0 & 2.0 & 32.9339 & $\\dots$ \\\\\n",
       "\t17 & 5.0 & 8.0 & 3.0 & 28.6167 & $\\dots$ \\\\\n",
       "\t18 & 13.0 & 6.0 & 3.0 & 41.7026 & $\\dots$ \\\\\n",
       "\t19 & 8.0 & 7.0 & 3.0 & 26.5198 & $\\dots$ \\\\\n",
       "\t20 & 8.0 & 5.0 & 3.0 & 39.5016 & $\\dots$ \\\\\n",
       "\t21 & 10.0 & 5.0 & 3.0 & 31.3761 & $\\dots$ \\\\\n",
       "\t22 & 8.0 & 6.0 & 3.0 & 39.784 & $\\dots$ \\\\\n",
       "\t23 & 8.0 & 6.0 & 3.0 & 38.0686 & $\\dots$ \\\\\n",
       "\t24 & 8.0 & 6.0 & 3.0 & 38.3748 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m99960×21 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m Delay_from_due_date \u001b[0m\u001b[1m Num_of_Delayed_Payment \u001b[0m\u001b[1m Num_Credit_Inquiries \u001b[0m\u001b[1m Cr\u001b[0m ⋯\n",
       "       │\u001b[90m Float64             \u001b[0m\u001b[90m Float64                \u001b[0m\u001b[90m Float64              \u001b[0m\u001b[90m Fl\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │                 3.0                     7.0                   4.0     ⋯\n",
       "     2 │                 3.0                     7.0                   4.0\n",
       "     3 │                 3.0                     7.0                   4.0\n",
       "     4 │                 5.0                     4.0                   4.0\n",
       "     5 │                 6.0                     4.0                   4.0     ⋯\n",
       "     6 │                 8.0                     4.0                   4.0\n",
       "     7 │                 3.0                     8.0                   4.0\n",
       "     8 │                 3.0                     6.0                   4.0\n",
       "   ⋮   │          ⋮                     ⋮                      ⋮               ⋱\n",
       " 99954 │                23.0                     6.0                   3.0     ⋯\n",
       " 99955 │                20.0                     6.0                   3.0\n",
       " 99956 │                23.0                     7.0                   3.0\n",
       " 99957 │                18.0                     7.0                   3.0\n",
       " 99958 │                27.0                     6.0                   3.0     ⋯\n",
       " 99959 │                20.0                     6.0                   3.0\n",
       " 99960 │                18.0                     6.0                   3.0\n",
       "\u001b[36m                                               18 columns and 99945 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data = CSV.read(joinpath(_PATH_TO_DATA, \"credit_score_dataset.csv\"), DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734d62d3",
   "metadata": {},
   "source": [
    "Next, let's do some data wrangling. In particular, we will convert the categorical variables to numerical variables, and then z-score the numerical variables (excluding the label variable). \n",
    "* The `Payment_of_Min_Amount` variable is a categorical variable with levels: `No`, abd `Yes`. Let's convert it to a numerical variable with levels: `No` $\\rightarrow$ `-1` and `Yes` $\\rightarrow$ `1`.\n",
    "* The `Credit_Score` variable is a categorical variable with levels: `Poor`, `Standard`, and `Good`. Let's convert it to a numerical variable with levels: `Poor` $\\rightarrow$ `1`, `Standard` $\\rightarrow$ `2`, and `Good` $\\rightarrow$ `3`.\n",
    "* The `Credit_Mix` variable is a categorical variable with levels: `Bad`, `Standard`, and `Good`. Let's convert it to a numerical variable with levels: `Bad` $\\rightarrow$ `1`, `Standard` $\\rightarrow$ `2`, and `Good` $\\rightarrow$ `3`.\n",
    "The `Payment_Behaviour` variable is a categorical variable with multiple levels. Let's convert these to a numerical variable with levels: `Low_spent_Small_value_payments` $\\rightarrow$ `1`, `Low_spent_Medium_value_payments` $\\rightarrow$ `2`, `Low_spent_Large_value_payments` $\\rightarrow$ `3`, `High_spent_Small_value_payments` $\\rightarrow$ `4`, `High_spent_Medium_value_payments` $\\rightarrow$ `5`, and `High_spent_Large_value_payments` $\\rightarrow$ `6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec015540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>99960×21 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">99935 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">Delay_from_due_date</th><th style = \"text-align: left;\">Num_of_Delayed_Payment</th><th style = \"text-align: left;\">Num_Credit_Inquiries</th><th style = \"text-align: left;\">Credit_Utilization_Ratio</th><th style = \"text-align: left;\">Credit_History_Age</th><th style = \"text-align: left;\">Payment_of_Min_Amount</th><th style = \"text-align: left;\">Amount_invested_monthly</th><th style = \"text-align: left;\">Monthly_Balance</th><th style = \"text-align: left;\">Credit_Score</th><th style = \"text-align: left;\">Credit_Mix</th><th style = \"text-align: left;\">Payment_Behaviour</th><th style = \"text-align: left;\">Age</th><th style = \"text-align: left;\">Annual_Income</th><th style = \"text-align: left;\">Num_Bank_Accounts</th><th style = \"text-align: left;\">Num_Credit_Card</th><th style = \"text-align: left;\">Interest_Rate</th><th style = \"text-align: left;\">Num_of_Loan</th><th style = \"text-align: left;\">Monthly_Inhand_Salary</th><th style = \"text-align: left;\">Changed_Credit_Limit</th><th style = \"text-align: left;\">Outstanding_Debt</th><th style = \"text-align: left;\">Total_EMI_per_month</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">-1.22042</td><td style = \"text-align: right;\">-1.01059</td><td style = \"text-align: right;\">-0.459468</td><td style = \"text-align: right;\">-1.06743</td><td style = \"text-align: right;\">0.440109</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.581417</td><td style = \"text-align: right;\">-0.424237</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.954179</td><td style = \"text-align: right;\">-0.819564</td><td style = \"text-align: right;\">-0.914032</td><td style = \"text-align: right;\">-0.741333</td><td style = \"text-align: right;\">-1.31966</td><td style = \"text-align: right;\">0.190514</td><td style = \"text-align: right;\">-0.744377</td><td style = \"text-align: right;\">0.134091</td><td style = \"text-align: right;\">-0.53368</td><td style = \"text-align: right;\">-0.445004</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">-1.22042</td><td style = \"text-align: right;\">-1.01059</td><td style = \"text-align: right;\">-0.459468</td><td style = \"text-align: right;\">-0.0663653</td><td style = \"text-align: right;\">0.440109</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.387021</td><td style = \"text-align: right;\">-0.554212</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.954179</td><td style = \"text-align: right;\">-0.819564</td><td style = \"text-align: right;\">-0.914032</td><td style = \"text-align: right;\">-0.741333</td><td style = \"text-align: right;\">-1.31966</td><td style = \"text-align: right;\">0.190514</td><td style = \"text-align: right;\">-0.744377</td><td style = \"text-align: right;\">0.134091</td><td style = \"text-align: right;\">-0.53368</td><td style = \"text-align: right;\">-0.445004</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">-1.22042</td><td style = \"text-align: right;\">-1.01059</td><td style = \"text-align: right;\">-0.459468</td><td style = \"text-align: right;\">-0.718247</td><td style = \"text-align: right;\">0.46017</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.574824</td><td style = \"text-align: right;\">-0.336938</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.954179</td><td style = \"text-align: right;\">-0.819564</td><td style = \"text-align: right;\">-0.914032</td><td style = \"text-align: right;\">-0.741333</td><td style = \"text-align: right;\">-1.31966</td><td style = \"text-align: right;\">0.190514</td><td style = \"text-align: right;\">-0.744377</td><td style = \"text-align: right;\">0.134091</td><td style = \"text-align: right;\">-0.53368</td><td style = \"text-align: right;\">-0.445004</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">-1.08554</td><td style = \"text-align: right;\">-1.48906</td><td style = \"text-align: right;\">-0.459468</td><td style = \"text-align: right;\">-0.177194</td><td style = \"text-align: right;\">0.470201</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">0.0297401</td><td style = \"text-align: right;\">-0.839574</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.954179</td><td style = \"text-align: right;\">-0.819564</td><td style = \"text-align: right;\">-0.914032</td><td style = \"text-align: right;\">-0.741333</td><td style = \"text-align: right;\">-1.31966</td><td style = \"text-align: right;\">0.190514</td><td style = \"text-align: right;\">-0.744377</td><td style = \"text-align: right;\">0.134091</td><td style = \"text-align: right;\">-0.53368</td><td style = \"text-align: right;\">-0.445004</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">-1.0181</td><td style = \"text-align: right;\">-1.48906</td><td style = \"text-align: right;\">-0.459468</td><td style = \"text-align: right;\">-1.46323</td><td style = \"text-align: right;\">0.480231</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.781615</td><td style = \"text-align: right;\">-0.288991</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.954179</td><td style = \"text-align: right;\">-0.819564</td><td style = \"text-align: right;\">-0.914032</td><td style = \"text-align: right;\">-0.741333</td><td style = \"text-align: right;\">-1.31966</td><td style = \"text-align: right;\">0.190514</td><td style = \"text-align: right;\">-0.744377</td><td style = \"text-align: right;\">0.134091</td><td style = \"text-align: right;\">-0.53368</td><td style = \"text-align: right;\">-0.445004</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">-0.88321</td><td style = \"text-align: right;\">-1.48906</td><td style = \"text-align: right;\">-0.459468</td><td style = \"text-align: right;\">-0.981512</td><td style = \"text-align: right;\">0.490262</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.673751</td><td style = \"text-align: right;\">-0.293702</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.954179</td><td style = \"text-align: right;\">-0.819564</td><td style = \"text-align: right;\">-0.914032</td><td style = \"text-align: right;\">-0.741333</td><td style = \"text-align: right;\">-1.31966</td><td style = \"text-align: right;\">0.190514</td><td style = \"text-align: right;\">-0.744377</td><td style = \"text-align: right;\">0.134091</td><td style = \"text-align: right;\">-0.53368</td><td style = \"text-align: right;\">-0.445004</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">-1.22042</td><td style = \"text-align: right;\">-0.851097</td><td style = \"text-align: right;\">-0.459468</td><td style = \"text-align: right;\">-1.90486</td><td style = \"text-align: right;\">0.500292</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.0786576</td><td style = \"text-align: right;\">-0.741088</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.954179</td><td style = \"text-align: right;\">-0.819564</td><td style = \"text-align: right;\">-0.914032</td><td style = \"text-align: right;\">-0.741333</td><td style = \"text-align: right;\">-1.31966</td><td style = \"text-align: right;\">0.190514</td><td style = \"text-align: right;\">-0.744377</td><td style = \"text-align: right;\">0.134091</td><td style = \"text-align: right;\">-0.53368</td><td style = \"text-align: right;\">-0.445004</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">-1.22042</td><td style = \"text-align: right;\">-1.17008</td><td style = \"text-align: right;\">-0.459468</td><td style = \"text-align: right;\">-1.632</td><td style = \"text-align: right;\">0.500292</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.867017</td><td style = \"text-align: right;\">-0.211398</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.954179</td><td style = \"text-align: right;\">-0.819564</td><td style = \"text-align: right;\">-0.914032</td><td style = \"text-align: right;\">-0.741333</td><td style = \"text-align: right;\">-1.31966</td><td style = \"text-align: right;\">0.190514</td><td style = \"text-align: right;\">-0.744377</td><td style = \"text-align: right;\">0.134091</td><td style = \"text-align: right;\">-0.53368</td><td style = \"text-align: right;\">-0.445004</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">-1.22042</td><td style = \"text-align: right;\">-1.48906</td><td style = \"text-align: right;\">-0.977305</td><td style = \"text-align: right;\">-1.52837</td><td style = \"text-align: right;\">0.981756</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.458836</td><td style = \"text-align: right;\">0.313664</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">-0.489597</td><td style = \"text-align: right;\">-0.4087</td><td style = \"text-align: right;\">-1.29988</td><td style = \"text-align: right;\">-0.741333</td><td style = \"text-align: right;\">-0.976448</td><td style = \"text-align: right;\">-1.0359</td><td style = \"text-align: right;\">-0.363666</td><td style = \"text-align: right;\">-0.76441</td><td style = \"text-align: right;\">-0.711087</td><td style = \"text-align: right;\">-0.689468</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">-0.950653</td><td style = \"text-align: right;\">-1.96753</td><td style = \"text-align: right;\">-0.977305</td><td style = \"text-align: right;\">1.22463</td><td style = \"text-align: right;\">0.991786</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.786897</td><td style = \"text-align: right;\">0.378503</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">-0.489597</td><td style = \"text-align: right;\">-0.4087</td><td style = \"text-align: right;\">-1.29988</td><td style = \"text-align: right;\">-0.741333</td><td style = \"text-align: right;\">-0.976448</td><td style = \"text-align: right;\">-1.0359</td><td style = \"text-align: right;\">-0.363666</td><td style = \"text-align: right;\">-0.76441</td><td style = \"text-align: right;\">-0.711087</td><td style = \"text-align: right;\">-0.689468</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">-1.22042</td><td style = \"text-align: right;\">-1.96753</td><td style = \"text-align: right;\">-0.977305</td><td style = \"text-align: right;\">0.183785</td><td style = \"text-align: right;\">1.00182</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.693846</td><td style = \"text-align: right;\">0.293961</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">-0.489597</td><td style = \"text-align: right;\">-0.4087</td><td style = \"text-align: right;\">-1.29988</td><td style = \"text-align: right;\">-0.741333</td><td style = \"text-align: right;\">-0.976448</td><td style = \"text-align: right;\">-1.0359</td><td style = \"text-align: right;\">-0.363666</td><td style = \"text-align: right;\">-0.76441</td><td style = \"text-align: right;\">-0.711087</td><td style = \"text-align: right;\">-0.689468</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">-1.22042</td><td style = \"text-align: right;\">-1.64855</td><td style = \"text-align: right;\">-0.977305</td><td style = \"text-align: right;\">1.34811</td><td style = \"text-align: right;\">1.01185</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.484432</td><td style = \"text-align: right;\">0.290275</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">-0.489597</td><td style = \"text-align: right;\">-0.4087</td><td style = \"text-align: right;\">-1.29988</td><td style = \"text-align: right;\">-0.741333</td><td style = \"text-align: right;\">-0.976448</td><td style = \"text-align: right;\">-1.0359</td><td style = \"text-align: right;\">-0.363666</td><td style = \"text-align: right;\">-0.76441</td><td style = \"text-align: right;\">-0.711087</td><td style = \"text-align: right;\">-0.689468</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">-1.22042</td><td style = \"text-align: right;\">-1.96753</td><td style = \"text-align: right;\">-0.977305</td><td style = \"text-align: right;\">0.526365</td><td style = \"text-align: right;\">1.02188</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.32626</td><td style = \"text-align: right;\">0.193211</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">-0.489597</td><td style = \"text-align: right;\">-0.4087</td><td style = \"text-align: right;\">-1.29988</td><td style = \"text-align: right;\">-0.741333</td><td style = \"text-align: right;\">-0.976448</td><td style = \"text-align: right;\">-1.0359</td><td style = \"text-align: right;\">-0.363666</td><td style = \"text-align: right;\">-0.76441</td><td style = \"text-align: right;\">-0.711087</td><td style = \"text-align: right;\">-0.689468</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99949</td><td style = \"text-align: right;\">0.802856</td><td style = \"text-align: right;\">1.86024</td><td style = \"text-align: right;\">0.835122</td><td style = \"text-align: right;\">-0.738006</td><td style = \"text-align: right;\">-1.49577</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0.104284</td><td style = \"text-align: right;\">-0.911422</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">-0.489597</td><td style = \"text-align: right;\">-0.796355</td><td style = \"text-align: right;\">1.78693</td><td style = \"text-align: right;\">1.19319</td><td style = \"text-align: right;\">1.65482</td><td style = \"text-align: right;\">0.599318</td><td style = \"text-align: right;\">-0.711406</td><td style = \"text-align: right;\">1.21536</td><td style = \"text-align: right;\">1.8569</td><td style = \"text-align: right;\">-0.35448</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99950</td><td style = \"text-align: right;\">0.802856</td><td style = \"text-align: right;\">1.86024</td><td style = \"text-align: right;\">0.835122</td><td style = \"text-align: right;\">0.210175</td><td style = \"text-align: right;\">-1.48574</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">-0.61247</td><td style = \"text-align: right;\">-0.446789</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">-0.489597</td><td style = \"text-align: right;\">-0.796355</td><td style = \"text-align: right;\">1.78693</td><td style = \"text-align: right;\">1.19319</td><td style = \"text-align: right;\">1.65482</td><td style = \"text-align: right;\">0.599318</td><td style = \"text-align: right;\">-0.711406</td><td style = \"text-align: right;\">1.21536</td><td style = \"text-align: right;\">1.8569</td><td style = \"text-align: right;\">-0.35448</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99951</td><td style = \"text-align: right;\">0.802856</td><td style = \"text-align: right;\">2.01973</td><td style = \"text-align: right;\">0.835122</td><td style = \"text-align: right;\">-1.39949</td><td style = \"text-align: right;\">-1.48574</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">-0.104679</td><td style = \"text-align: right;\">-0.814856</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">-0.489597</td><td style = \"text-align: right;\">-0.796355</td><td style = \"text-align: right;\">1.78693</td><td style = \"text-align: right;\">1.19319</td><td style = \"text-align: right;\">1.65482</td><td style = \"text-align: right;\">0.599318</td><td style = \"text-align: right;\">-0.711406</td><td style = \"text-align: right;\">1.21536</td><td style = \"text-align: right;\">1.8569</td><td style = \"text-align: right;\">-0.35448</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99952</td><td style = \"text-align: right;\">0.802856</td><td style = \"text-align: right;\">1.86024</td><td style = \"text-align: right;\">0.835122</td><td style = \"text-align: right;\">0.949061</td><td style = \"text-align: right;\">-1.46568</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">-0.816306</td><td style = \"text-align: right;\">-0.308237</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">-0.489597</td><td style = \"text-align: right;\">-0.796355</td><td style = \"text-align: right;\">1.78693</td><td style = \"text-align: right;\">1.19319</td><td style = \"text-align: right;\">1.65482</td><td style = \"text-align: right;\">0.599318</td><td style = \"text-align: right;\">-0.711406</td><td style = \"text-align: right;\">1.21536</td><td style = \"text-align: right;\">1.8569</td><td style = \"text-align: right;\">-0.35448</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99953</td><td style = \"text-align: right;\">0.12843</td><td style = \"text-align: right;\">-1.17008</td><td style = \"text-align: right;\">-0.718386</td><td style = \"text-align: right;\">0.138129</td><td style = \"text-align: right;\">1.54346</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">1.06545</td><td style = \"text-align: right;\">-0.99728</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.768346</td><td style = \"text-align: right;\">-0.283847</td><td style = \"text-align: right;\">-0.52818</td><td style = \"text-align: right;\">0.225926</td><td style = \"text-align: right;\">-0.862045</td><td style = \"text-align: right;\">-0.627096</td><td style = \"text-align: right;\">-0.262794</td><td style = \"text-align: right;\">0.169417</td><td style = \"text-align: right;\">-0.799942</td><td style = \"text-align: right;\">-0.560016</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99954</td><td style = \"text-align: right;\">0.12843</td><td style = \"text-align: right;\">-1.17008</td><td style = \"text-align: right;\">-0.718386</td><td style = \"text-align: right;\">-0.615432</td><td style = \"text-align: right;\">1.55349</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.0663926</td><td style = \"text-align: right;\">-0.0155823</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.768346</td><td style = \"text-align: right;\">-0.283847</td><td style = \"text-align: right;\">-0.52818</td><td style = \"text-align: right;\">0.225926</td><td style = \"text-align: right;\">-0.862045</td><td style = \"text-align: right;\">-0.627096</td><td style = \"text-align: right;\">-0.262794</td><td style = \"text-align: right;\">0.169417</td><td style = \"text-align: right;\">-0.799942</td><td style = \"text-align: right;\">-0.560016</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99955</td><td style = \"text-align: right;\">-0.0738981</td><td style = \"text-align: right;\">-1.17008</td><td style = \"text-align: right;\">-0.718386</td><td style = \"text-align: right;\">1.37565</td><td style = \"text-align: right;\">1.56352</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.272528</td><td style = \"text-align: right;\">0.0317699</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.768346</td><td style = \"text-align: right;\">-0.283847</td><td style = \"text-align: right;\">-0.52818</td><td style = \"text-align: right;\">0.225926</td><td style = \"text-align: right;\">-0.862045</td><td style = \"text-align: right;\">-0.627096</td><td style = \"text-align: right;\">-0.262794</td><td style = \"text-align: right;\">0.169417</td><td style = \"text-align: right;\">-0.799942</td><td style = \"text-align: right;\">-0.560016</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99956</td><td style = \"text-align: right;\">0.12843</td><td style = \"text-align: right;\">-1.01059</td><td style = \"text-align: right;\">-0.718386</td><td style = \"text-align: right;\">0.464936</td><td style = \"text-align: right;\">1.57355</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.68124</td><td style = \"text-align: right;\">0.356463</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.768346</td><td style = \"text-align: right;\">-0.283847</td><td style = \"text-align: right;\">-0.52818</td><td style = \"text-align: right;\">0.225926</td><td style = \"text-align: right;\">-0.862045</td><td style = \"text-align: right;\">-0.627096</td><td style = \"text-align: right;\">-0.262794</td><td style = \"text-align: right;\">0.169417</td><td style = \"text-align: right;\">-0.799942</td><td style = \"text-align: right;\">-0.560016</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99957</td><td style = \"text-align: right;\">-0.208783</td><td style = \"text-align: right;\">-1.01059</td><td style = \"text-align: right;\">-0.718386</td><td style = \"text-align: right;\">1.61838</td><td style = \"text-align: right;\">1.58358</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.716076</td><td style = \"text-align: right;\">0.434758</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.768346</td><td style = \"text-align: right;\">-0.283847</td><td style = \"text-align: right;\">-0.52818</td><td style = \"text-align: right;\">0.225926</td><td style = \"text-align: right;\">-0.862045</td><td style = \"text-align: right;\">-0.627096</td><td style = \"text-align: right;\">-0.262794</td><td style = \"text-align: right;\">0.169417</td><td style = \"text-align: right;\">-0.799942</td><td style = \"text-align: right;\">-0.560016</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99958</td><td style = \"text-align: right;\">0.3982</td><td style = \"text-align: right;\">-1.17008</td><td style = \"text-align: right;\">-0.718386</td><td style = \"text-align: right;\">1.75321</td><td style = \"text-align: right;\">1.59362</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.870902</td><td style = \"text-align: right;\">0.528782</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.768346</td><td style = \"text-align: right;\">-0.283847</td><td style = \"text-align: right;\">-0.52818</td><td style = \"text-align: right;\">0.225926</td><td style = \"text-align: right;\">-0.862045</td><td style = \"text-align: right;\">-0.627096</td><td style = \"text-align: right;\">-0.262794</td><td style = \"text-align: right;\">0.169417</td><td style = \"text-align: right;\">-0.799942</td><td style = \"text-align: right;\">-0.560016</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99959</td><td style = \"text-align: right;\">-0.0738981</td><td style = \"text-align: right;\">-1.17008</td><td style = \"text-align: right;\">-0.718386</td><td style = \"text-align: right;\">0.264548</td><td style = \"text-align: right;\">1.60365</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">0.297805</td><td style = \"text-align: right;\">-0.393121</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.768346</td><td style = \"text-align: right;\">-0.283847</td><td style = \"text-align: right;\">-0.52818</td><td style = \"text-align: right;\">0.225926</td><td style = \"text-align: right;\">-0.862045</td><td style = \"text-align: right;\">-0.627096</td><td style = \"text-align: right;\">-0.262794</td><td style = \"text-align: right;\">0.169417</td><td style = \"text-align: right;\">-0.799942</td><td style = \"text-align: right;\">-0.560016</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99960</td><td style = \"text-align: right;\">-0.208783</td><td style = \"text-align: right;\">-1.17008</td><td style = \"text-align: right;\">-0.718386</td><td style = \"text-align: right;\">0.372867</td><td style = \"text-align: right;\">1.61368</td><td style = \"text-align: right;\">-1</td><td style = \"text-align: right;\">-0.136056</td><td style = \"text-align: right;\">-0.0455783</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">-0.768346</td><td style = \"text-align: right;\">-0.283847</td><td style = \"text-align: right;\">-0.52818</td><td style = \"text-align: right;\">0.225926</td><td style = \"text-align: right;\">-0.862045</td><td style = \"text-align: right;\">-0.627096</td><td style = \"text-align: right;\">-0.262794</td><td style = \"text-align: right;\">0.169417</td><td style = \"text-align: right;\">-0.799942</td><td style = \"text-align: right;\">-0.560016</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& Delay\\_from\\_due\\_date & Num\\_of\\_Delayed\\_Payment & Num\\_Credit\\_Inquiries & Credit\\_Utilization\\_Ratio & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & -1.22042 & -1.01059 & -0.459468 & -1.06743 & $\\dots$ \\\\\n",
       "\t2 & -1.22042 & -1.01059 & -0.459468 & -0.0663653 & $\\dots$ \\\\\n",
       "\t3 & -1.22042 & -1.01059 & -0.459468 & -0.718247 & $\\dots$ \\\\\n",
       "\t4 & -1.08554 & -1.48906 & -0.459468 & -0.177194 & $\\dots$ \\\\\n",
       "\t5 & -1.0181 & -1.48906 & -0.459468 & -1.46323 & $\\dots$ \\\\\n",
       "\t6 & -0.88321 & -1.48906 & -0.459468 & -0.981512 & $\\dots$ \\\\\n",
       "\t7 & -1.22042 & -0.851097 & -0.459468 & -1.90486 & $\\dots$ \\\\\n",
       "\t8 & -1.22042 & -1.17008 & -0.459468 & -1.632 & $\\dots$ \\\\\n",
       "\t9 & -1.22042 & -1.48906 & -0.977305 & -1.52837 & $\\dots$ \\\\\n",
       "\t10 & -0.950653 & -1.96753 & -0.977305 & 1.22463 & $\\dots$ \\\\\n",
       "\t11 & -1.22042 & -1.96753 & -0.977305 & 0.183785 & $\\dots$ \\\\\n",
       "\t12 & -1.22042 & -1.64855 & -0.977305 & 1.34811 & $\\dots$ \\\\\n",
       "\t13 & -1.22042 & -1.96753 & -0.977305 & 0.526365 & $\\dots$ \\\\\n",
       "\t14 & -1.22042 & -2.12702 & -0.977305 & 0.214284 & $\\dots$ \\\\\n",
       "\t15 & -1.22042 & -1.48906 & -0.977305 & -0.225301 & $\\dots$ \\\\\n",
       "\t16 & -1.22042 & -1.48906 & -0.977305 & 0.126896 & $\\dots$ \\\\\n",
       "\t17 & -1.08554 & -0.851097 & -0.718386 & -0.716805 & $\\dots$ \\\\\n",
       "\t18 & -0.545997 & -1.17008 & -0.718386 & 1.84058 & $\\dots$ \\\\\n",
       "\t19 & -0.88321 & -1.01059 & -0.718386 & -1.12661 & $\\dots$ \\\\\n",
       "\t20 & -0.88321 & -1.32957 & -0.718386 & 1.41045 & $\\dots$ \\\\\n",
       "\t21 & -0.748325 & -1.32957 & -0.718386 & -0.177529 & $\\dots$ \\\\\n",
       "\t22 & -0.88321 & -1.17008 & -0.718386 & 1.46563 & $\\dots$ \\\\\n",
       "\t23 & -0.88321 & -1.17008 & -0.718386 & 1.13039 & $\\dots$ \\\\\n",
       "\t24 & -0.88321 & -1.17008 & -0.718386 & 1.19022 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m99960×21 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m Delay_from_due_date \u001b[0m\u001b[1m Num_of_Delayed_Payment \u001b[0m\u001b[1m Num_Credit_Inquiries \u001b[0m\u001b[1m Cr\u001b[0m ⋯\n",
       "       │\u001b[90m Float64             \u001b[0m\u001b[90m Float64                \u001b[0m\u001b[90m Float64              \u001b[0m\u001b[90m Fl\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │          -1.22042                 -1.01059              -0.459468     ⋯\n",
       "     2 │          -1.22042                 -1.01059              -0.459468\n",
       "     3 │          -1.22042                 -1.01059              -0.459468\n",
       "     4 │          -1.08554                 -1.48906              -0.459468\n",
       "     5 │          -1.0181                  -1.48906              -0.459468     ⋯\n",
       "     6 │          -0.88321                 -1.48906              -0.459468\n",
       "     7 │          -1.22042                 -0.851097             -0.459468\n",
       "     8 │          -1.22042                 -1.17008              -0.459468\n",
       "   ⋮   │          ⋮                     ⋮                      ⋮               ⋱\n",
       " 99954 │           0.12843                 -1.17008              -0.718386     ⋯\n",
       " 99955 │          -0.0738981               -1.17008              -0.718386\n",
       " 99956 │           0.12843                 -1.01059              -0.718386\n",
       " 99957 │          -0.208783                -1.01059              -0.718386\n",
       " 99958 │           0.3982                  -1.17008              -0.718386     ⋯\n",
       " 99959 │          -0.0738981               -1.17008              -0.718386\n",
       " 99960 │          -0.208783                -1.17008              -0.718386\n",
       "\u001b[36m                                               18 columns and 99945 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = let\n",
    "    \n",
    "    dataset = copy(raw_data); # make a copy of the raw data, so we can keep the original intact\n",
    "    transform!(dataset, :Payment_of_Min_Amount => ByRow(x -> (x==\"No\" ? -1 : 1)) => :Payment_of_Min_Amount); # maps Payment_of_Min_Amount to -1,1\n",
    "    transform!(dataset, :Credit_Score => ByRow(s -> convertcreditscore(s))  => :Credit_Score); # maps Credit_Score to 1,2,3\n",
    "    transform!(dataset, :Credit_Mix => ByRow(s -> convertcreditmix(s))  => :Credit_Mix); # maps Credit_Mix to 1,2,3\n",
    "    transform!(dataset, :Payment_Behaviour => ByRow(s -> convertcreditbehavior(s))  => :Payment_Behaviour); # maps Payment_Behaviour to 1,2,3,4,5,6\n",
    "    categorical_fields = [\"Credit_Mix\", \"Payment_Behaviour\", \"Credit_Score\", \"Payment_of_Min_Amount\"];\n",
    "\n",
    "    # names to convert -\n",
    "    all_names = names(dataset)\n",
    "    names_to_convert = Set{String}()\n",
    "    for name in all_names\n",
    "        if (in(name, categorical_fields) == false)\n",
    "            push!(names_to_convert, name)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # z-score standardization\n",
    "    for name in names_to_convert\n",
    "        name_symbol = Symbol(name);\n",
    "        μ = mean(dataset[!, name_symbol])\n",
    "        σ = std(dataset[!, name_symbol])\n",
    "        transform!(dataset, name_symbol => ByRow(x -> (x - μ) / σ) => name_symbol); # standardize Delay_from_due_date\n",
    "    end\n",
    "\n",
    "    # convert categorical fields to categorical    \n",
    "    dataset;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638c6b0",
   "metadata": {},
   "source": [
    "Next, let's package the whole dataset into a `Vector{Tuple{Vector{Float32}, OneHotVector{UInt32}}}` data structure. We'll split the data into a training set and a test set in a few operations from now. The training set will be used to train the model, and the test set will be used to evaluate the model's performance.\n",
    "* _Hmmm_? This is a strange data structure format. However, if we look more closely, this is a direct code representation of the $\\mathcal{D}$ dataset. Moreover, the training loop for our classifier can take this data format directly, making training super easy and convenient! Also, notice: We convert everything to `Float32` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e57b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_dataset, features = let\n",
    "    converted_dataset = Vector{Tuple{Vector{Float32}, OneHotVector{UInt32}}}();\n",
    "    number_digit_array = [1,2,3]; # this is the digits for the labels\n",
    "\n",
    "    # which cols do we want to use as features - let's use all *but* the label -\n",
    "    all_cols = names(dataset);\n",
    "    features = Array{String,1}();\n",
    "    for col in all_cols\n",
    "        if col != :Credit_Score\n",
    "            push!(features, col);\n",
    "        end\n",
    "    end\n",
    "    features = features |> sort;\n",
    "    number_of_features = length(features);\n",
    "    \n",
    "    # build record tuples -\n",
    "    for record ∈ eachrow(dataset)\n",
    "\n",
    "        # convert the label to a one-hot vector\n",
    "        label = record[:Credit_Score]; # this is the label we want to predict \n",
    "        Y = onehot(label, number_digit_array); # convert the label to a one-hot vector\n",
    "        X = Vector{Float32}();\n",
    "\n",
    "        for i ∈ eachindex(features)\n",
    "            feature = features[i]; # get the feature name\n",
    "            value = record[feature] |> Float32; # get the value of the feature\n",
    "            push!(X, value); # add the value to the feature vector\n",
    "        end\n",
    "\n",
    "        data_tuple = (X, Y); # create a tuple of the feature vector and the label\n",
    "        push!(converted_dataset, data_tuple); # add the tuple to the dataset\n",
    "    end\n",
    "\n",
    "    converted_dataset, features;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137e76b7",
   "metadata": {},
   "source": [
    "__Constants:__ Let's set up some constants that we will use throughout the problem set. See the comments next to each constant for a description of what it is, permissible values, its default value, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9a77738",
   "metadata": {},
   "outputs": [],
   "source": [
    "θ = 0.60; # what fraction of the data to use for training. Default is 80%\n",
    "number_of_training_samples = Int64(θ * length(converted_dataset)); # θ of the data will be used for training\n",
    "number_of_test_samples = length(converted_dataset) - number_of_training_samples; # the rest will be used for testing\n",
    "numner_of_features = length(features); # the number of features, i.e, the length of x\n",
    "number_of_classes = 3; # the number of classes for the problem {Poor | Standard | Good}\n",
    "number_of_epochs = 25; # how many epochs do we want to train for?\n",
    "number_of_hidden_nodes = 2^10; # TODO: Change the width of the hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fc30a3",
   "metadata": {},
   "source": [
    "Finally, let's set up the `training_dataset::Vector{Tuple{Vector{Float32}, OneHotVector{UInt32}}}` and `test_dataset::Vector{Tuple{Vector{Float32}, OneHotVector{UInt32}}}` variables. The training dataset will be used to train the model, and the test dataset will be used to evaluate the model's performance.\n",
    "* The training dataset will be a random sample of $\\theta$% of the records in the scaled dataset. We will compute the indices of the training dataset using [the `rand(...)` method](https://docs.julialang.org/en/v1/stdlib/Random/#Base.rand}) in combination with [the `Set` datastructure](https://docs.julialang.org/en/v1/base/collections/#Base.Set) to ensure that the training data has unique indices.\n",
    "* The test dataset will be the remaining $\\left(1-\\theta\\right)$% of the records in the scaled dataset. We will compute the indices of the test dataset using [the `setdiff(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.setdiff) to ensure that the test data has unique indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ace1e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset, test_dataset = let\n",
    "    \n",
    "    # initialize -\n",
    "    training_dataset = Vector{Tuple{Vector{Float32}, OneHotVector{UInt32}}}();\n",
    "    test_dataset = Vector{Tuple{Vector{Float32}, OneHotVector{UInt32}}}();\n",
    "    number_of_samples = length(converted_dataset);\n",
    "    all_index_set = range(1, stop=number_of_samples, step=1) |> Set{Int64};\n",
    "\n",
    "    # generate a set of random indices for training and testing -\n",
    "    random_training_index_set = Set{Int64}();\n",
    "    while length(random_training_index_set) ≤ number_of_training_samples\n",
    "        random_index = rand(1:number_of_samples);\n",
    "        push!(random_training_index_set, random_index);\n",
    "    end\n",
    "    random_test_index_set = setdiff(all_index_set, random_training_index_set); # the rest of the indices will be used for testing\n",
    "    \n",
    "    # populate the training set -\n",
    "    random_training_index_vector = random_training_index_set |> collect;\n",
    "    for i ∈ eachindex(random_training_index_vector)\n",
    "        index = random_training_index_vector[i];\n",
    "        push!(training_dataset, converted_dataset[index]);\n",
    "    end\n",
    "    \n",
    "    # populate the test set -\n",
    "    random_test_index_vector = random_test_index_set |> collect;\n",
    "    for i ∈ eachindex(random_test_index_vector)\n",
    "        index = random_test_index_vector[i];\n",
    "        push!(test_dataset, converted_dataset[index]);\n",
    "    end\n",
    "\n",
    "    # return -\n",
    "    training_dataset, test_dataset;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb8db6d",
   "metadata": {},
   "source": [
    "## Task 2: Construct and Train a Feedforward Credit Score Classifier\n",
    "In this task, we'll construct and train a feedforward neural network model using the training records encoded in the `training_dataset::Vector{Tuple{Vector{Float32}, OneHotVector{UInt32}}}` array. This model will classify consumers' credit scores based on their features. We will use [the `Flux.jl` package](https://github.com/FluxML/Flux.jl) to build and train the model.\n",
    "\n",
    "We build an empty model with default (random) parameter values but a fixed structure. The number and dimension of the layers and the activation functions for each layer are specified when we build the model (but we'll update the parameters during training).\n",
    "* _Library_: We use [the `Flux.jl` machine learning library](https://github.com/FluxML/Flux.jl) to construct the neural network model. The model will have three layers: the input layer is a `number_of_features` $\\times$ `number_of_hidden_nodes` layer with [tanh activation functions](https://en.wikipedia.org/wiki/Hyperbolic_functions#Tanh), the hidden layer is a `number_of_hidden_nodes` $\\times$ `number_of_classes` layer and the output layer is the [softmax function](https://en.wikipedia.org/wiki/Softmax_function).\n",
    "* _Syntax_: The [`Flux.jl` package](https://github.com/FluxML/Flux.jl) uses some next level syntax. The model is built using [the `Chain` function](https://fluxml.ai/Flux.jl/stable/reference/models/layers/#Flux.Chain), which takes a list of layers as input. Each layer is defined using the [`Dense` type](https://fluxml.ai/Flux.jl/stable/reference/models/layers/#Flux.Dense) (in this case), which takes the number of input and output neurons as arguments. The activation function is an additional argument to [the `Dense` type](https://fluxml.ai/Flux.jl/stable/reference/models/layers/#Flux.Dense). The final layer uses [the `softmax(...)` method exported by the `NNlib.jl` package](https://fluxml.ai/NNlib.jl/dev/reference/#Softmax) to produce a probability distribution over the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d1c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment the code below to build the model!\n",
    "Flux.@layer MyFluxNeuralNetworkModel  trainable=(input, middle, hidden); # create a \"namespaced\" of sorts\n",
    "MyModel() = MyFluxNeuralNetworkModel( # a strange type of constructor\n",
    "    Chain(\n",
    "        input = Dense(numner_of_features, number_of_hidden_nodes, tanh_fast),  # layer 1\n",
    "        hidden = Dense(number_of_hidden_nodes, number_of_classes, tanh_fast), # layer 2\n",
    "        output = NNlib.softmax) # layer 3 (output layer)\n",
    ");\n",
    "model = MyModel().chain;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02bebb5",
   "metadata": {},
   "source": [
    "__Loss function__: Next, specify the _loss function_ we will minimize to estimate the model parameters. We'll choose a loss function that is appropriate for a _multiclass classification problem_, namely a [logit cross-entropy loss function](https://fluxml.ai/Flux.jl/stable/reference/models/losses/#Flux.Losses.logitcrossentropy):\n",
    "$$\n",
    "\\mathcal{L}(\\theta) = -\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{C} y_{ij}\\log(p_{ij}(\\theta))\n",
    "$$\n",
    "where the outer summation is over all $N$ training examples, and the inner summation is over the $C$ possible classes. The $y_{ij}$ is the one-hot encoded label for the $i$-th training example, and $p_{ij}$ is the predicted probability of the $i$-th training example being in class $j$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "624ffafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Uncomment below to setup the loss function -\n",
    "loss(ŷ, y) = Flux.Losses.logitcrossentropy(ŷ, y; agg = mean); # loss for training multiclass classifiers, what is the agg?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb72c657",
   "metadata": {},
   "source": [
    "__Optimizer__. We'll use [Gradient descent with momentum](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Momentum) where the `λ` parameter denotes the `learning rate` and `β` denotes the momentum parameter. We save information about the optimizer in the `opt_state` variable, which will eventually get passed to the training method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea8a5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "λ = 0.61; # TODO: maybe change the learning rate (default: 0.61)?\n",
    "β = 0.10; # TODO: maybe change the momentum parameter (default: 0.10)?\n",
    "opt_state = Flux.setup(Momentum(λ,β), model);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6ca1b8",
   "metadata": {},
   "source": [
    "We are now ready to train the model. If the `should_we_train = true,` then we use the [Gradient descent with momentum](https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Momentum) to minimize a [logit cross-entropy loss function](https://fluxml.ai/Flux.jl/stable/reference/models/losses/#Flux.Losses.logitcrossentropy).\n",
    "* _Restart_: Because the error landscape is non-convex, we must start from many different locations. We do `number_of_epochs` passes through the data, i.e., a forward pass for prediction and a backpropagation step for parameter updates. Although the training is a little opaque, intuition suggests that the library chooses different initial parameter guesses for each pass through the data and then drives these to convergence.\n",
    "* _Training takes a long time_. For each complete pass through the data, i.e., for each `epoch,` we save a `tmp` file holding the network state... just in case of `BOOOOOOOOM.`  We also have some pre-trained models to load if the `should_we_train = false.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80a2bbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Epoch $(i) of $(number_of_epochs) completed\" = \"Epoch 2 of 25 completed\"\n",
      "\"Epoch $(i) of $(number_of_epochs) completed\" = \"Epoch 4 of 25 completed\"\n",
      "\"Epoch $(i) of $(number_of_epochs) completed\" = \"Epoch 6 of 25 completed\"\n",
      "\"Epoch $(i) of $(number_of_epochs) completed\" = \"Epoch 8 of 25 completed\"\n",
      "\"Epoch $(i) of $(number_of_epochs) completed\" = \"Epoch 10 of 25 completed\"\n",
      "\"Epoch $(i) of $(number_of_epochs) completed\" = \"Epoch 12 of 25 completed\"\n",
      "\"Epoch $(i) of $(number_of_epochs) completed\" = \"Epoch 14 of 25 completed\"\n",
      "\"Epoch $(i) of $(number_of_epochs) completed\" = \"Epoch 16 of 25 completed\"\n",
      "\"Epoch $(i) of $(number_of_epochs) completed\" = \"Epoch 18 of 25 completed\"\n",
      "\"Epoch $(i) of $(number_of_epochs) completed\" = \"Epoch 20 of 25 completed\"\n",
      "\"Epoch $(i) of $(number_of_epochs) completed\" = \"Epoch 22 of 25 completed\"\n",
      "\"Epoch $(i) of $(number_of_epochs) completed\" = \"Epoch 24 of 25 completed\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  input = Dense(21 => 1024, tanh_fast),  \u001b[90m# 22_528 parameters\u001b[39m\n",
       "  hidden = Dense(1024 => 3, tanh_fast),  \u001b[90m# 3_075 parameters\u001b[39m\n",
       "  output = NNlib.softmax,\n",
       ") \u001b[90m                  # Total: 4 arrays, \u001b[39m25_603 parameters, 100.215 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainedmodel = let\n",
    "\n",
    "    should_we_train = true; # TODO: set this flag to {true | false}\n",
    "    \n",
    "    # training loop -\n",
    "    localmodel = model; # make a local copy of the model\n",
    "    if (should_we_train == true)\n",
    "        for i = 1:number_of_epochs    \n",
    "            \n",
    "            # train the model - check out the do block notion: https://docs.julialang.org/en/v1/base/base/#do\n",
    "            Flux.train!(localmodel, training_dataset, opt_state) do m, x, y\n",
    "                loss(m(x), y)\n",
    "            end\n",
    "        \n",
    "            # let the user know how we are doing -\n",
    "            if (rem(i,2) == 0)\n",
    "                @show \"Epoch $i of $number_of_epochs completed\" # print the epoch number\n",
    "            end\n",
    "        \n",
    "            # save the state of the model, in case something happens. We can reload from this state\n",
    "            jldsave(joinpath(_PATH_TO_DATA, \"tmp-model-training-checkpoint.jld2\"), model_state = Flux.state(localmodel))    \n",
    "        end\n",
    "    else\n",
    "        # if we don't train: load up a previous model\n",
    "        model_state = JLD2.load(joinpath(_PATH_TO_DATA, \"Model-training-N$(number_of_hidden_nodes).jld2\"), \"model_state\");\n",
    "        Flux.loadmodel!(localmodel, model_state);\n",
    "    end\n",
    "    localmodel; # return the *trained* model (either freshly trained or loaded from a saved file)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd8329c",
   "metadata": {},
   "source": [
    "## Task 3: Does the model generalize?\n",
    "In this task, we'll check the feedforward network's ability to generalize, i.e., calculate how well the network classifies records it has not seen. We'll compute the fraction of the training and test data that is correctly classified, and answer some design questions.\n",
    "\n",
    "Let's start by computing the fraction of the `training_data` records that are correctly classified. This will help us understand how many of the `n` training samples we get correct and how many we get wrong. We expect to be _mostly correct_ on the training data.\n",
    "\n",
    "In the code block below, we pass feature vectors $\\mathbf{x}$ into the `model` instance, compute the predicted label `ŷ,` and compare the predicted and actual labels for the `training_dataset.`\n",
    "* _Logic_: If the prediction and the actual label agree, we update the `S` variable (a running count of the number of correct classifications). Finally, we compute the fraction of _correct_ classifications by dividing the number of correct predictions by the total number of images in the `training` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a4c9027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification on the training data: 82.16%\n"
     ]
    }
   ],
   "source": [
    "let \n",
    "    S_training = 0;\n",
    "    number_digit_array = [1,2,3]; # this is the digits for the labels\n",
    "    for i ∈ eachindex(training_dataset)\n",
    "    \n",
    "        x = training_dataset[i][1];\n",
    "        y = training_dataset[i][2];\n",
    "        ŷ = trainedmodel(x) |> z-> argmax(z) |> z-> number_digit_array[z] |> z-> onehot(z,number_digit_array)\n",
    "        y == ŷ ? S_training +=1 : nothing\n",
    "    end\n",
    "    correct_prediction_training = (S_training/number_of_training_samples)*100 |> x-> round(x, digits=2);\n",
    "    println(\"Correct classification on the training data: $(correct_prediction_training)%\");\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aefc55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_I_see_a_traning_error_number = true; # TODO: set this flag to {true | false}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ea9751",
   "metadata": {},
   "source": [
    "Next, look at the classification performance on the `test_dataset`. In the code block below, we pass feature vectors $\\mathbf{x}$ into the `trainedmodel` instance, compute the predicted label `ŷ,` and compare the predicted and actual labels for the `training_dataset.` The logic is the same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ad69959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct classification on the test data: 81.81%\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    S_testing = 0;\n",
    "    number_digit_array = [1,2,3]; # this is the digits for the labels\n",
    "    for i ∈ eachindex(test_dataset)\n",
    "    \n",
    "        x = test_dataset[i][1];\n",
    "        y = test_dataset[i][2];\n",
    "        ŷ = trainedmodel(x) |> z-> argmax(z) |> z-> number_digit_array[z] |> z-> onehot(z, number_digit_array)\n",
    "        y == ŷ ? S_testing+=1 : nothing\n",
    "    end\n",
    "    correct_prediction_test = (S_testing/number_of_test_samples)*100 |> x-> round(x, digits=2);\n",
    "    println(\"Correct classification on the test data: $(correct_prediction_test)%\");\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62e5373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_I_see_a_test_error_number = true; # TODO: set this flag to {true | false}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c87651",
   "metadata": {},
   "source": [
    "### Discussion Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e51664a",
   "metadata": {},
   "source": [
    "__DQ1__: How sensitive is the model to the training data? Does it _overfit_, i.e., does it perform well on the training data but poorly on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40272d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your answer to DQ (either as a commented code cell, or as a markdown cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a3fea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_I_answer_DQ1 = true; # TODO: Update this value {true | false} based on whether you answered DQ1 or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d0f10",
   "metadata": {},
   "source": [
    "__DQ2__: We made many design choices regarding the model architecture (layers, activation functions, etc.), the loss function, and the optimizer. The best performance that I've found so far (with the default design reported in the solution) is approximately 82% % correct classification (on both training and test). \n",
    "* _Can we improve_? How do our design choices affect the model's performance? What would you change if you had to do it again? What would you keep the same? Implement one of your ideas, run the training loop, and report the results. Do we beat 82\\%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30cc4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Put your answer to DQ (either as a commented code cell, or as a markdown cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d53837f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_I_answer_DQ2 = true; # TODO: Update this value {true | false} based on whether you answered DQ2 or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588d86bc",
   "metadata": {},
   "source": [
    "## Tests\n",
    "In the code block below, we check some values in your notebook and give you feedback on which items are correct or different. `Unhide` the code block below (if you are curious) about how we implemented the tests and what we are testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9e98713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1mTest Summary:                           | \u001b[22m\u001b[32m\u001b[1mPass  \u001b[22m\u001b[39m\u001b[36m\u001b[1mTotal  \u001b[22m\u001b[39m\u001b[0m\u001b[1mTime\u001b[22m\n",
      "CHEME 5820 Problem Set 5 Test Suite     | \u001b[32m  11  \u001b[39m\u001b[36m   11  \u001b[39m\u001b[0m0.3s\n",
      "  Task 1: Setup, Prerequisites and Data | \u001b[32m   3  \u001b[39m\u001b[36m    3  \u001b[39m\u001b[0m0.3s\n",
      "  Task 2: Model                         | \u001b[32m   4  \u001b[39m\u001b[36m    4  \u001b[39m\u001b[0m0.0s\n",
      "  Task 3: Generalization                | \u001b[32m   4  \u001b[39m\u001b[36m    4  \u001b[39m\u001b[0m0.0s\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    @testset verbose = true \"CHEME 5820 Problem Set 5 Test Suite\" begin\n",
    "\n",
    "        @testset \"Task 1: Setup, Prerequisites and Data\" begin\n",
    "            @test _DID_INCLUDE_FILE_GET_CALLED == true\n",
    "            @test isempty(training_dataset) == false\n",
    "            @test isempty(test_dataset) == false\n",
    "        end\n",
    "\n",
    "        @testset \"Task 2: Model\" begin\n",
    "            @test isnothing(model) == false\n",
    "            @test isnothing(λ) == false\n",
    "            @test isnothing(β) == false\n",
    "            @test isnothing(trainedmodel) == false\n",
    "        end\n",
    "\n",
    "        @testset \"Task 3: Generalization\" begin\n",
    "            @test do_I_see_a_traning_error_number  == true # Test training error\n",
    "            @test do_I_see_a_test_error_number  == true # Test test error\n",
    "            @test did_I_answer_DQ1 == true # Test DQ1 answer\n",
    "            @test did_I_answer_DQ2 == true # Test DQ1 answer\n",
    "        end\n",
    "    end\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
